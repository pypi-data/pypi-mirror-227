import{SelectInputView}from"../enumerable.mjs";import{RepeatableInputView}from"../parent.mjs";import{NumberInputView,FloatInputView}from"../numeric.mjs";import{PromptInputView}from"./prompts.mjs";class OutputScaleInputView extends SelectInputView{static defaultOptions={1:"1× (no upscale)",2:"2×",4:"4×",8:"8×",16:"16×"};static tooltip="The output scale will multiply the height and width of the generated image by this amount after the image has been generated. For example, an image generated at 512×512 with an output scale of 2× will result in a final image at 1024×1024.<br /><strong>Caution!</strong> Large values, especially coupled with larger input sizes, can result in an image that will be too large for your browser to display, and it will crash. The resulting images are still saved.";static defaultValue="1"}class UpscaleAmountInputView extends SelectInputView{static defaultOptions={2:"2×",4:"4×",8:"8×",16:"16×"};static defaultValue="2"}class UpscaleMethodInputView extends SelectInputView{static defaultOptions={esrgan:"ESRGAN",esrganime:"ESRGANime",gfpgan:"GFPGAN",lanczos:"Lanczos",bicubic:"Bicubic",bilinear:"Bilinear",nearest:"Nearest"};static defaultValue="esrgan"}class UpscaleDiffusionControlnetInputView extends SelectInputView{static defaultOptions={tile:"Tile",canny:"Canny Edge Detection",hed:"HED (Holistically-Nested Edge Detection)",mlsd:"MLSD (Mobile Line Segment Detection)"};static defaultValue="tile"}class UpscaleMethodsInputView extends RepeatableInputView{static minimumItems=1;static maximumItems=5;static memberClass=UpscaleMethodInputView;static tooltip="The upscaling method has a significant effect on the output image. The best general-purpose upscaling method is selected by default.<br />When selecting multiple methods, the first is used for the first upscale, the second for the second (when using iterative upscaling), etc.<br /><strong>ESRGAN</strong>: Short for Enhanced Super-Resolution Generative Adversarial Network, this is an AI upscaling method that tries to maintain sharp edges where they should be sharp, and soft where they should be soft, filling in details along the way.<br /><strong>ESRGANime</strong>: Similar to the above, but with sharper lines for cartoon or anime style.<br /><strong>GFPGAN</strong>: Short for Generative Facial Prior Generative Adversarial Network, this is an AI Upscaling method with face restoration. This results in photorealistic faces more often than not, but can erase desired features; it is best paired with upscale diffusion.<br /><strong>Lanczos</strong>: An algorithm with blurry but consistent results.<br /><strong>Bicubic</strong>: An algorithm that can result in slightly sharper edges than Lanczos, but can have jagged edges on curves and diagonal lines.<br /><strong>Bilinear</strong>: A very fast algorithm with overall the blurriest results.<br /><strong>Nearest</strong>: Maintain sharp pixel boundaries, resulting in a pixelated or retro look."}class UpscaleDiffusionIterativeControlnetInputView extends RepeatableInputView{static maximumItems=5;static minimumItems=0;static memberClass=UpscaleDiffusionControlnetInputView;static tooltip="The controlnet to use during upscaling. None are required, and using one will result in significant slowdowns during upscaling, but can result in a more consistent upscaled image. When using multiple methods, the first is used for the first upscale, the second is used for the second (when using iterative upscaling), etc.<br /><strong>Tile</strong>: This network is trained on large images and slices of their images.<br /><strong>Canny Edge</strong>: This network is trained on images and the edges of that image after having run through Canny Edge detection. The output image will be processed with this algorithm.<br /><strong>HED</strong>: Short for Holistically-Nested Edge Detection, this edge-detection algorithm is best used when the input image is too blurry or too noisy for Canny Edge detection.<br /><strong>MLSD</strong>: Short for Mobile Line Segment Detection, this edge-detection algorithm searches only for straight lines, and is best used for geometric or architectural images."}class UpscaleDiffusionPromptInputView extends RepeatableInputView{static maximumItems=5;static memberClass=PromptInputView;static tooltip="The prompt to use when upscaling, it is generally best to use generic detail-oriented prompts, unless there are specific things or people you want to ensure have details.<br />When using multiple prompts, the first is used for the first upscale, the second is used for the second (when using iterative upscaling), etc."}class UpscaleDiffusionNegativePromptInputView extends UpscaleDiffusionPromptInputView{static tooltip="The negative prompt to use when upscaling, it is generally best to use generic negative prompts, unless there are specific things you don't want.<br />When using multiple prompts, the first is used for the first upscale, the second is used for the second (when using iterative upscaling), etc."}class UpscaleDiffusionStrengthInputView extends RepeatableInputView{static memberClass=FloatInputView;static memberConfig={min:0,value:.2,max:1,step:.01};static minimumItems=1;static maximumItems=5;static tooltip="The amount to change the image when upscaling, from 0 to 1. Keep this low to improve consistency in the upscaled image, or increase it to add many details for a tableau or panorama style.<br />When using multiple strengths, the first is used for the first upscale, the second is used for the second (when using iterative upscaling), etc."}class UpscaleDiffusionStepsInputView extends RepeatableInputView{static memberClass=NumberInputView;static memberConfig={min:0,max:1e3,value:100};static minimumItems=1;static maximumItems=5;static tooltip="The number of inference steps to make during the denoising loop of the upscaled image. Higher values can result in more details but can also take significantly longer, especially with high denoising strengths.<br />When using multiple step amounts, the first is used for the first upscale, the second is used for the second (when using iterative upscaling), etc."}class UpscaleDiffusionGuidanceScaleInputView extends RepeatableInputView{static memberClass=FloatInputView;static memberConfig={min:0,max:100,value:12,step:.1};static minimumItems=1;static maximumItems=5;static tooltip="The amount to adhere to the prompts during upscaling. Higher values can result in more details but less consistency.<br />When using multiple guidance scales, the first is used for the first upscale, the second is used for the second (when using iterative upscaling), etc."}class UpscaleDiffusionPipelineInputView extends SelectInputView{static defaultOptions={base:"Always Use Base Pipeline"};static allowEmpty=!0;static placeholder="Use Refiner Pipeline when Available";static tooltip="When re-diffusing upscaled samples, you can use the base pipeline, or the refiner pipeline, when one is present. Generally the refiner is better tuned for this task, but change this option to always use the base pipeline instead."}export{OutputScaleInputView,UpscaleAmountInputView,UpscaleMethodsInputView,UpscaleDiffusionIterativeControlnetInputView,UpscaleDiffusionPromptInputView,UpscaleDiffusionNegativePromptInputView,UpscaleDiffusionStepsInputView,UpscaleDiffusionStrengthInputView,UpscaleDiffusionPipelineInputView,UpscaleDiffusionGuidanceScaleInputView};
