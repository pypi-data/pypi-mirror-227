{"Blur":{"body":"### Syntax\n\n```\nBlur[]\n```\n\n### Examples\n\nThe following example loads an image, detects people, blurs them, and displays the new image.\n\n```\nLoad[\"./photo.jpg\"]\nDetect[\"person\"]\nBlur[]\nShow[]\n```"},"Break":{"body":"### Syntax\n\n```\nIn[\"./folder/\"]\n    ...\n    If[...]\n        Break[]\n```\n\n### Examples\n\nThe following example loads a folder of images, looks for a cat in each image, and exits the loop if more than three cats were found in an image:\n\n```\nIn[\"./folder/\"]\n    Load[]\n    Detect[\"cat\"]\n    If[Count[] > 3]\n        Break[]\n```"},"Breakpoint":{"body":"### Syntax\n\n```\nBreakpoint[]\n```\n\n### Examples\n\nThe following example loads an image, then detects cats in the image. A breakpoint runs which starts an interactive [debugging session](/debugging). Once exiting from the debugging session, the program continues to run.\n\n```\nLoad[\"./image.jpg\"]\nDetect[\"cat\"]\nBreakpoint[]\nIf[Count[] > 4]\n    Say[\"There are more than four cats in this image!\"]\n```"},"Caption":{"body":"<div class=\"note\">\n<p>The model behind Detect[] will be downloaded automatically the first time you use it on your computer. This can take a few minutes depending on your internet connection.</p>\n</div>\n\n### Syntax\n\n```\nCaption[]\n```\n\n### Examples\n\nThe following example loads an image, generates a caption, and displays the results.\n\n```\nLoad[\"./tmp/bus.jpg\"]\nGetEdges[]\nShow[]\n```\n\n![A caption reading \"a bus is driving down the street in front of a building\"](/assets/caption.png)\n\n### Supported Models\n\n- [BLIP](https://github.com/salesforce/BLIP)"},"Classify":{"body":"Classify[] uses a zero-shot model which means you can specify any class you like.\n\n<div class=\"note\">\n<p>The model behind Classify[] will be downloaded automatically the first time you use it on your computer. This can take a few minutes depending on your internet connection.</p>\n</div>\n\n### Syntax\n\n```\nClassify[\"cat\", \"dog\"]\n```\n\n### Arguments\n\n- An arbitrary number of `class` arguments that specify the labels to use in classification.\n\n### Examples\n\nThe following example loads an image, classifies if the image is a cat or a dog, and displays the results.\n\n```\nLoad[\"./tmp/cat.jpg\"]\nClassify[\"cat\", \"dog\"]\nShow[]\n```\n\n![A photo of a cat classified as a cat](/assets/classify.png)\n\n### Supported Models\n\n- [CLIP](https://github.com/openai/clip)"},"Compare":{"body":"If you have called `Detect[]` or `Segment[]`, the respective bounding boxes or masks will be shown on the image.\n\n### Syntax\n\n```\nCompare[]\n```\n\n### Examples\n\nIn this example, two images are loaded and displayed size-by-side for comparison.\n\n```\nLoad[\"./photo.jpg\"]\nLoad[\"./photo1.jpg\"]\nCompare[]\n```"},"Count":{"body":"### Syntax\n\n```\nCount[]\n```\n\n### Examples\n\nThe following example loads an image, detects all the people in the image, counts the number of people, and says how many were identified in the image.\n\n```\nLoad[\"./photo.jpg\"]\nDetect[\"person\"]\nCount[]\nSay[]\n```\n\n![A photo of people outside with a count below indicating there are eight people in the image](/assets/count.png)"},"CountInRegion":{"body":"### Syntax\n\n```\nCountInRegion[x, y, width, height]\n```\n\n## Arguments\n\n- `x` - The x coordinate of the top left corner of the region.\n- `y` - The y coordinate of the top left corner of the region.\n- `width` - The width of the region.\n- `height` - The height of the region.\n\n### Examples\n\nThe following example loads an image, detects all the people in the image, gets the number of people in a region of the image, and shows how many detections were identified in the region.\n\n```\nLoad[\"./photo.jpg\"]\nDetect[\"person\"]\nCountInRegion[0, 0, 100, 100]\nSay[]\n```"},"Cutout":{"body":"### Syntax\n\n```\nCutout[]\n```\n\n### Examples\n\nIn this example, an image is loaded, faces are detected, and the first face is cut out and added to the image stack. The original image preserves the cut out area.\n\n```\nLoad[\"./photo.jpg\"]\nDetect[\"face\"]\nCompare[]\n```"},"Describe":{"body":"A synonym for <a href=\"/docs/caption\">Caption[]</a>."},"Detect":{"body":"Detect[] uses a zero-shot model which means you can specify any class you like.\n\n<div class=\"note\">\n<p>The model behind Detect[] will be downloaded automatically the first time you use it on your computer. This can take a few minutes depending on your internet connection.</p>\n</div>\n\n### Syntax\n\n```\nDetect[]\nDetect[\"person\"]\n```\n\n### Arguments\n\n- `class` - The class to detect.\n\n### Examples\n\nThe following example loads an image, runs inference to find all objects matching the \"person\" class, and displays the results.\n\n```\nLoad[\"./photo.jpg\"]\nDetect[\"person\"]\nShow[]\n```\n\n### Supported Models\n\n- [Grounding DINO](https://github.com/IDEA-Research/GroundingDINO)\n- [Ultralytics YOLOv8 (COCO checkpoint)](https://github.com/ultralytics/ultralytics)\n\n### Synonyms\n\n- Find[]"},"Equality (==, !=)":{"body":"### Syntax\n\n```\nx == y\nx != y\n```\n\n### Arguments\n\n- `x` - The first statement to evaluate\n- `y` - The second statemenet to evaluate\n\n### Examples\n\nThe following example loads an image, reads the text in the image, and shows the image if it contains \"tea\".\n\n```\nLoad[\"./photo.jpg\"]\nGetText[]\nIf[Read[] == \"tea\"]\n    Show[]\n```"},"Exit":{"body":"### Syntax\n\n```\nExit[]\n```"},"FilterByClass":{"body":"You can set a class filter before or after you run `Detect[]` or `Segment[]`. By default, no classes are filtered.\n\nTo reset the class filter, use `FilterByClass[]`.\n\n### Syntax\n\n```\nFilterByClass[]\nFilterByClass[class]\nFilterByClass[class1, class2, ...]\n```\n\n### Arguments\n\n- `class`: The class(es) to filter by. Can be a single class or a list of classes.\n\n### Examples\n\nThe following example finds cats in an image called `house.jpg`. `Detect[]` finds all the objects in the image. Then, a filter is applied so that only cats are used in future cells. Then, the cat predictions are displayed on the `house.jpg` image that was loaded at the beginning of the example.\n\n```\nLoad[\"./house.jpg\"]\nDetect[\"cat\"]\nSetConfidence[90]\nShow[]\n```"},"Find":{"body":"A synonym for <a href=\"/docs/detect\">Detect[]</a>."},"GetDistinctScenes":{"body":"You can only use this function after you have used `In[\"video.mov\"]` on a video and applied a `Classify[]` operation to each frame.\n\n### Syntax\n\n```\nGetDistinctScenes[]\n```\n\n### Examples\n\nThe following example loads a video, classifies each frame, and returns the timestamps at which classifications change:\n\n```\nIn[\"video.mov\"]\n    Classify[\"sports\", \"cafe\", \"beach\"]\n\nGetDistinctScenes[]\n```"},"GetEdges":{"body":"### Syntax\n\n```\nGetEdges[]\n```\n\n### Arguments\n\n- `confidence`: The confidence threshold value represented as a percentage whole number (i.e. 20, 50, 90).\n\n### Examples\n\nThe following example loads an image, gets the edges of objects in the image using Sobel edge detection, and shows the results of the Sobel edge detection process.\n\n```\nLoad[\"./tmp/bus.jpg\"]\nGetEdges[]\nShow[]\n```\n\n![A bus with Sobel edge detection applied to it](/assets/get_edges.png)"},"GetFPS":{"body":"### Syntax\n\n```\nGetFPS[]\n```\n\n### Examples\n\nThe following example loads a webcam, gets the webcam stream FPS, writes the FPS to the top left corner of the image, and displays the resultant image:\n\n```\nUseCamera[]\n    GetFPS[]\n    Read[]\n    WriteText[]\n```"},"GetText":{"body":"### Syntax\n\n```\nGetText[]\n```\n\n### Examples\n\nThe following example loads an image, retrieves the text, and displays it.\n\n```\nLoad[\"./photo.jpg\"]\nGetText[]\nSay[]\n```"},"Greyscale":{"body":"### Syntax\n\n```\nGreyscale[]\n```\n\n### Examples\n\nThe following example loads an image, converts it to greyscale, and displays it.\n\n```\nLoad[\"./photo.jpg\"]\nGreyscale[]\nShow[]\n```"},"If":{"body":"### Syntax\n\n```\nIf[statement]\n    ...\n```\n\n### Arguments\n\n- `statement`: A statement to evaluate. The statement must evaluate to `True` or `False`. Statements can also be comparisons using `>`, `<`, `>=`, `<=`, `==`, and `!=`.\n- `...`: An arbitrary number of commands indented with a tab character. These commands are run if the `if` statement evaluates to `True`.\n\n### Examples\n\nThe following example loads an image, reads the text in the image, and shows the image if it contains \"tea\".\n\n```\nLoad[\"./photo.jpg\"]\nGetText[]\nIf[Read[] == \"tea\"]\n    Show[]\n```\n\nIn this example, `Read[] == \"tea\"` is the statement to evaluate. If this statement returns `True`, the indented statements are run. Otherwise, the indented statements are not run."},"Import":{"body":"### Syntax\n\n```\nImport[\"./file.vic\"]\n```\n\n### Arguments\n\n- `path` - The path to the .vic file to import.\n\n### Examples\n\nThe following example laods a .vic file and calls a function within it:\n\n```\nImport[\"./counter.vic]\n\ncountcars\nSay[]\n```"},"In":{"body":"### Syntax\n\n```\nIn[\"./folder/\"]\n    ...\n```\n\n### Arguments\n\n- `query` - The text query.\n- `...` - Statements to evaluate for each image in the specified folder.\n\n### Examples\n\nThe following example loads a folder of images, searches for images related to a plane, and displays the images ordered by relevance in descending order.\n\n```\nIn[\"./folder/\"]\n    Load[]\n\nSearch[\"plane\"]\nCompare[]\n```"},"Input":{"body":"Inputs let you accept image or text input from a user.\n\nInputs are used as part of VisionScript Cloud, a method through which you can deploy code to an API or a HTML web page that you can share with others.\n\nIf a script contains an `Input[]`, it cannot be executed as a VisionScript script from the command line or a notebook environment. We recommend adding `Input[]` when you have already written the logic for your program and are ready to share it with the world.\n\n### Syntax\n\n```\nInput[\"Form Name\"]\n```\n\n### Arguments\n\n- `Form Name`: A unique identifier for the input. This will be shown as the form name in VisionScript Cloud deployments.\n\n### Examples\n\nThe following example asks a user to provide an imagei and will classify whether the image is a cat or a dog. The text response is then displayed.\n\n```\nLoad[Input[]]\nClassify[\"cat\", \"dog\"]\nShow[]\n```"},"Load":{"body":"### Examples\n\n```\nLoad[\"./photo.jpg\"]\nLoad[\"https://example.com/photo.jpg\"]\nLoad[\"./folder/\"]\n```\n\n### Arguments\n\n- `path` - The path to the image or folder to load.\n\n### Example\n\nThe following example loads an image and displays it.\n\n```\nLoad[\"./photo.jpg\"]\nShow[]\n```"},"Make":{"body":"### Syntax\n\n#### Declaration\n\n```\nMake showgreyscale\n    ...\n```\n\n#### Call\n\n```\nshowgreyscale[]\n```\n\n### Arguments\n\n- `name` - The name of the function.\n- `...` - The body of the function.\n\n### Examples\n\nThe following example declares a function that converts an image to greyscale and displays it.\n\nThis function is applied to all images in a folder.\n\n```\nMake showgreyscale\n    Greyscale[]\n    Show[]\n\nIn[\"./folder\"]\n    showgreyscale[]\n```"},"Paste":{"body":"### Syntax\n\n```\nPaste[x, y]\n```\n\n### Arguments\n\n- `x` - The x position to start pasting the image.\n- `y` - The y position to start pasting the image.\n\n### Examples\n\nThe following example cuts out the first cat in an image then pastes it in the top corner of the image.\n\nThis function is applied to all images in a folder.\n\n```\nLoad[\"./image.jpg\"]\nDetect[\"cat\"]\nGet[1]\nCutout[]\nPaste[0, 0]\n```"},"PasteRandom":{"body":"### Syntax\n\n```\nPasteRandom[]\n```\n\n### Examples\n\nThe following example cuts out the first cat in an image then pastes it at a random x, y coordinate in the image.\n\nThis function is applied to all images in a folder.\n\n```\nLoad[\"./image.jpg\"]\nDetect[\"cat\"]\nGet[1]\nCutout[]\nPasteRandom[]\n```"},"Profile":{"body":"`Profile[]` groups run time by function rather than documenting the length of individual function calls.\n\n### Syntax\n\n```\nProfile[]\n```\n\n### Examples\n\nThe following code prints a statement saying how many cats are in an image if a cat is found in an image:\n\n```\nProfile[]\n\nLoad[\"./garden.jpg\"]\nDetect[\"cat\"]\nCount[]\nIf[Read[] > 0]\n    Say[]\nEnd\n\nSay[]\n```\n\nThe code starts with a `Profile[]` statement, which enables the profiler.\n\nThis code runs and then shows the following information:\n\n```\n--------------------\nProfile:\n--------------------\ndetect : 5.28s\nread : 0.00s\ngt : 0.00s\nexpr : 0.00s\nload : 0.00s\nsay : 0.00s\ncount : 0.00s\nif : 0.00s\nmake : 0.00s\nTotal run time: 5.28s\n```\n\nHere, we can see program execution time as well as the time spent to run each function type."},"Read":{"body":"When writing an `if` statement, you may want to use a value from a previous computation.\n\nTo do so, you need to use `Read[]` to retrieve the last computed value before an if statement was evaluated.\n\n### Syntax\n\n```\nRead[]\n```\n\n### Examples\n\nThe following example loads an image, reads the text in the image, and shows the image if it contains \"tea\".\n\n```\nLoad[\"./photo.jpg\"]\nGetText[]\nIf[Read[] == \"tea\"]\n    Show[]\n```"},"ReadQR":{"body":"### Syntax\n\n```\nReadQR[]\n```\n\n### Examples\n\nThe following example loads an image, detects a QR code, and displays the text associated with the QR code.\n\n```\nLoad[\"./photo1.jpg\"]\nReadQR[]\nSay[]\n```"},"Replace":{"body":"### Syntax\n\n```\nReplace[]\nReplace[\"blue\"]\n```\n\n### Examples\n\nIn this example, an image is loaded, faces are detected, and the first face is replaced with a blue box. The new image is then saved to a file.\n\n```\nLoad[\"./photo.jpg\"]\nReplace[\"blue\"]\nSave[\"./new_photo.jpg\"]\n```"},"Reset":{"body":"### Syntax\n\n```\nReset[]\n```\n\n### Examples\n\nThe following example loads an image, detects solar panels, then clears the program state.\n\n```\nLoad[\"./photo.jpg\"]\nDetect[\"solar panel\"]\nReset[]\n```"},"Resize":{"body":"### Syntax\n\n```\nResize[100, 100]\n```\n\n### Arguments\n\n- `width` - The width to resize the image to.\n- `height` - The height to resize the image to.\n\n### Examples\n\nThe following example loads an image, resizes it to 100x100, and displays it.\n\n```\nLoad[\"./tmp/cat.jpg\"]\nResize[250, 250]\nShow[]\n```\n\n![A photo of a cat resized to 250x250](/assets/resize.png)"},"Rotate":{"body":"### Syntax\n\n```\nRotate[90]\n```\n\n### Arguments\n\n- `angle` - The angle to rotate the image by, in degrees.\n\n### Examples\n\nThe following example loads an image, rotates it by 90 degrees, and displays it.\n\n```\nLoad[\"./photo.jpg\"]\nRotate[90]\nShow[]\n```"},"Save":{"body":"You can save two types of data to a file:\n\n1. An image\n2. Detections from Detect[] or Segment[]\n\n### Syntax\n\n```\nSave[\"filename\"]\n```\n\n### Arguments\n\n- `filename` - The name of the file to save the image or detections to. Use `.csv` as the file extension to save detections. Use `.jpg` or `.png` to save an image.\n\n### Examples\n\n```\nLoad[\"./photo.jpg\"]\nDetect[\"people\"]\nSave[\"./photo_with_detections.jpg\"]\n```"},"Say":{"body":"### Syntax\n\n```\nSay[]\nSay[\"Hello, world!\"]\n```\n\n### Arguments\n\n- `message` - The message to say.\n\n### Examples\n\nThe following example runs inference on an image and prints the results.\n\n```\nLoad[\"./photo.jpg\"]\nDetect[\"person\"]\nSay[]\n```","signatures":["string","expr"]},"Search":{"body":"### Syntax\n\n```\nSearch[\"query\"]\n```\n\n### Arguments\n\n- `query` - The text query.\n\n### Examples\n\nThe following example loads a folder of images, searches for images related to a plane, and displays the images ordered by relevance in descending order.\n\n```\nIn[\"./folder/\"]\n    Load[]\n\nSearch[\"plane\"]\nCompare[]\n```"},"Segment":{"body":"Segment[] uses a zero-shot model which means you can specify any class you like.\n\n<div class=\"note\">\n<p>The model behind Segment[] will be downloaded automatically the first time you use it on your computer. This can take a few minutes depending on your internet connection.</p>\n</div>\n\n### Syntax\n\n```\nSegment[]\nSegment[\"person\"]\n```\n\n### Arguments\n\n- `class` - The class to detect.\n\n### Examples\n\nThe following example loads an image, runs inference to find all objects matching the \"person\" class, and displays the results.\n\n```\nLoad[\"./photo.jpg\"]\nSegment[\"person\"]\nShow[]\n```\n\n### Supported Models\n\n- [GroundedSAM](https://github.com/autodistill/autodistill-grounded-sam)"},"Select":{"body":"### Syntax\n\n```\nSelect[1]\n```\n\n### Arguments\n\n- `idx` - The index of the item to select.\n\n### Examples\n\nThe following example loads an image, finds all of the people, and retrieves the first three predictions.\n\n```\nLoad[\"./photo.jpg\"]\nSelect[3]\nShow[]\n```"},"SetBrightness":{"body":"### Syntax\n\n```\nSetBrightness[10]\n```\n\n### Arguments\n\n- `brightness` - The percentage by which to increase or decrease the brightness of the image. Minimum value is -100, maximum value is 100.\n\n### Examples\n\nThe following example loads an image, detects solar panels, increases the brightness of the solar panels by 10%, and displays the new image.\n\n```\nLoad[\"./photo.jpg\"]\nSegment[\"solar panel\"]\nSetBrightness[10]\nShow[]\n```"},"SetConfidence":{"body":"You can set the confidence threshold before or after you run `Detect[]` or `Segment[]`. The default confidence value is 50%.\n\n### Syntax\n\n```\nSetConfidence[]\nSetConfidence[confidence]\n```\n\n### Arguments\n\n- `confidence`: The confidence threshold value represented as a percentage whole number (i.e. 20, 50, 90). Min: 0, Max: 100. If no value is provided, the default value of 50 is used.\n\n### Examples\n\nThe following example finds cats in an image. `Detect[]` finds all the cats in the image. Then, a filter is applied so that only predictions with a confidence of 90% or higher are returned. Then, the predictions that meet the criteria are displayed on the image of the cat.\n\n```\nLoad[\"./cat.jpg\"]\nDetect[\"cat\"]\nSetConfidence[90]\nShow[]\n```"},"SetRegion":{"body":"SetRegion[] must be called before Detect[] or Segment[] to filter detections by region. If SetRegion[] is not called, the entire image is used as the region.\n\n### Syntax\n\n```\nSetRegion[x, y, width, height]\n```\n\n### Arguments\n\n- `x`, `y` - The x and y coordinates of the top left corner of the region.\n- `width`, `height` - The width and height of the region.\n\n### Examples\n\nThe following example loads an image and sets the region in which detections must appear to be returned by Detect[]. Then, Detect[] is run to detect solar panels. Predictions not in the specified region are not returned. Then, the filtered predictions are displayed on the the image on which detection was run.\n\nThe region is the top left quadrant of the image, assuming the image is 500x500 pixels.\n\n```\nLoad[\"./photo.jpg\"]\nSetRegion[0, 0, 250, 250]\nDetect[\"solar panel\"]\nShow[]\n```"},"Show":{"body":"If you have called `Detect[]` or `Segment[]`, the respective bounding boxes or masks will be shown on the image.\n\n### Syntax\n\n```\nShow[]\n```\n\n### Examples\n\nThe following example loads an image, detects the people, and displays the image with bounding boxes around the people.\n\n```\nLoad[\"./photo.jpg\"]\nDetect[\"person\"]\nShow[]\n```"},"ShowText":{"body":"### Syntax\n\n```\nUseCamera[]\n    ...\n```\n\nWhere `...` is the code you want to run on each frame in the image.\n\n### Examples\n\nThe following example loads a webcam, turns each frame greyscale, and shows the resultant frame:\n\n```\nUseCamera[]\n    Greyscale[]\n    Show[]\n```"},"Similarity":{"body":"### Syntax\n\n```\nSimilarity[]\nSimilarity[3]\n```\n\n### Arguments\n\n- `n` - The number of images to compare. Defaults to 2.\n\n### Examples\n\nThe following example loads two images, compares them, and displays a similarity score.\n\n```\nLoad[\"./photo.jpg\"]\nLoad[\"./photo1.jpg\"]\nSimilarity[]\nSay[]\n```"},"Size":{"body":"### Syntax\n\n```\nSize[]\n```\n\n### Examples\n\nThe following example loads a folder of images. The code displays each image in the folder, then prints out the size of each image to the console.\n\n```\nIn[\"./folder/\"]\n    Load[]\n    Show[]\n    Size[]\n```"},"Use":{"body":"### Syntax\n\n```\nUse[\"model\"]\n```\n\n### Examples\n\nThe following example declares that the YOLOv8 (COCO checkpoint) model should be used, before loading an image, detecting objects, and saying what they are.\n\n```\nUse[\"yolov8\"]\nLoad[\"./photo.jpg\"]\nDetect[]\nSay[]\n```\n\n### Supported Models\n\nSee Supported Models section in <a href=\"/docs/detect\">Detect[]</a>, <a href=\"/docs/segment\">Segment[]</a>, <a href=\"/docs/classify\">Classify[]</a>, and <a href=\"/docs/caption\">Caption[]</a> to find which models are supported for the task type you are using."}}