# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: yandex/cloud/ai/llm/v1alpha/llm_service.proto
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from yandex.cloud.ai.llm.v1alpha import llm_pb2 as yandex_dot_cloud_dot_ai_dot_llm_dot_v1alpha_dot_llm__pb2
from google.api import annotations_pb2 as google_dot_api_dot_annotations__pb2
from yandex.cloud import validation_pb2 as yandex_dot_cloud_dot_validation__pb2


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n-yandex/cloud/ai/llm/v1alpha/llm_service.proto\x12\x1byandex.cloud.ai.llm.v1alpha\x1a%yandex/cloud/ai/llm/v1alpha/llm.proto\x1a\x1cgoogle/api/annotations.proto\x1a\x1dyandex/cloud/validation.proto\"\xc4\x01\n\x0fInstructRequest\x12\x17\n\x05model\x18\x01 \x01(\tB\x08\x8a\xc8\x31\x04<=50\x12J\n\x12generation_options\x18\x02 \x01(\x0b\x32..yandex.cloud.ai.llm.v1alpha.GenerationOptions\x12\x1a\n\x10instruction_text\x18\x03 \x01(\tH\x00\x12\x16\n\x0crequest_text\x18\x04 \x01(\tH\x01\x42\r\n\x0bInstructionB\t\n\x07Request\"m\n\x10InstructResponse\x12>\n\x0c\x61lternatives\x18\x01 \x03(\x0b\x32(.yandex.cloud.ai.llm.v1alpha.Alternative\x12\x19\n\x11num_prompt_tokens\x18\x02 \x01(\x03\"\xd5\x01\n\x0b\x43hatRequest\x12\x17\n\x05model\x18\x01 \x01(\tB\x08\x8a\xc8\x31\x04<=50\x12J\n\x12generation_options\x18\x02 \x01(\x0b\x32..yandex.cloud.ai.llm.v1alpha.GenerationOptions\x12\x1a\n\x10instruction_text\x18\x03 \x01(\tH\x00\x12\x36\n\x08messages\x18\x04 \x03(\x0b\x32$.yandex.cloud.ai.llm.v1alpha.MessageB\r\n\x0bInstruction\"Y\n\x0c\x43hatResponse\x12\x35\n\x07message\x18\x01 \x01(\x0b\x32$.yandex.cloud.ai.llm.v1alpha.Message\x12\x12\n\nnum_tokens\x18\x02 \x01(\x03\"8\n\x0fTokenizeRequest\x12\x17\n\x05model\x18\x01 \x01(\tB\x08\x8a\xc8\x31\x04<=50\x12\x0c\n\x04text\x18\x02 \x01(\t\"F\n\x10TokenizeResponse\x12\x32\n\x06tokens\x18\x01 \x03(\x0b\x32\".yandex.cloud.ai.llm.v1alpha.Token2\xa2\x02\n\x15TextGenerationService\x12\x8b\x01\n\x08Instruct\x12,.yandex.cloud.ai.llm.v1alpha.InstructRequest\x1a-.yandex.cloud.ai.llm.v1alpha.InstructResponse\" \x82\xd3\xe4\x93\x02\x1a\"\x15/llm/v1alpha/instruct:\x01*0\x01\x12{\n\x04\x43hat\x12(.yandex.cloud.ai.llm.v1alpha.ChatRequest\x1a).yandex.cloud.ai.llm.v1alpha.ChatResponse\"\x1c\x82\xd3\xe4\x93\x02\x16\"\x11/llm/v1alpha/chat:\x01*0\x01\x32\x9e\x01\n\x10TokenizerService\x12\x89\x01\n\x08Tokenize\x12,.yandex.cloud.ai.llm.v1alpha.TokenizeRequest\x1a-.yandex.cloud.ai.llm.v1alpha.TokenizeResponse\" \x82\xd3\xe4\x93\x02\x1a\"\x15/llm/v1alpha/tokenize:\x01*Bf\n\x1fyandex.cloud.api.ai.llm.v1alphaZCgithub.com/yandex-cloud/go-genproto/yandex/cloud/ai/llm/v1alpha;llmb\x06proto3')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'yandex.cloud.ai.llm.v1alpha.llm_service_pb2', _globals)
if _descriptor._USE_C_DESCRIPTORS == False:

  DESCRIPTOR._options = None
  DESCRIPTOR._serialized_options = b'\n\037yandex.cloud.api.ai.llm.v1alphaZCgithub.com/yandex-cloud/go-genproto/yandex/cloud/ai/llm/v1alpha;llm'
  _INSTRUCTREQUEST.fields_by_name['model']._options = None
  _INSTRUCTREQUEST.fields_by_name['model']._serialized_options = b'\212\3101\004<=50'
  _CHATREQUEST.fields_by_name['model']._options = None
  _CHATREQUEST.fields_by_name['model']._serialized_options = b'\212\3101\004<=50'
  _TOKENIZEREQUEST.fields_by_name['model']._options = None
  _TOKENIZEREQUEST.fields_by_name['model']._serialized_options = b'\212\3101\004<=50'
  _TEXTGENERATIONSERVICE.methods_by_name['Instruct']._options = None
  _TEXTGENERATIONSERVICE.methods_by_name['Instruct']._serialized_options = b'\202\323\344\223\002\032\"\025/llm/v1alpha/instruct:\001*'
  _TEXTGENERATIONSERVICE.methods_by_name['Chat']._options = None
  _TEXTGENERATIONSERVICE.methods_by_name['Chat']._serialized_options = b'\202\323\344\223\002\026\"\021/llm/v1alpha/chat:\001*'
  _TOKENIZERSERVICE.methods_by_name['Tokenize']._options = None
  _TOKENIZERSERVICE.methods_by_name['Tokenize']._serialized_options = b'\202\323\344\223\002\032\"\025/llm/v1alpha/tokenize:\001*'
  _globals['_INSTRUCTREQUEST']._serialized_start=179
  _globals['_INSTRUCTREQUEST']._serialized_end=375
  _globals['_INSTRUCTRESPONSE']._serialized_start=377
  _globals['_INSTRUCTRESPONSE']._serialized_end=486
  _globals['_CHATREQUEST']._serialized_start=489
  _globals['_CHATREQUEST']._serialized_end=702
  _globals['_CHATRESPONSE']._serialized_start=704
  _globals['_CHATRESPONSE']._serialized_end=793
  _globals['_TOKENIZEREQUEST']._serialized_start=795
  _globals['_TOKENIZEREQUEST']._serialized_end=851
  _globals['_TOKENIZERESPONSE']._serialized_start=853
  _globals['_TOKENIZERESPONSE']._serialized_end=923
  _globals['_TEXTGENERATIONSERVICE']._serialized_start=926
  _globals['_TEXTGENERATIONSERVICE']._serialized_end=1216
  _globals['_TOKENIZERSERVICE']._serialized_start=1219
  _globals['_TOKENIZERSERVICE']._serialized_end=1377
# @@protoc_insertion_point(module_scope)
