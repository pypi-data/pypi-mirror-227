# Copyright 2023 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================
"""PPO Trainer"""
import mindspore
from mindspore import Tensor

from mindspore.ops import operations as P

from mindspore_rl.agent import trainer
from mindspore_rl.agent.trainer import Trainer
import mindspore
import mindspore.numpy as np
from mindspore_rl.core import MSRL
from mindspore_rl.agent import trainer
import mindspore.nn as nn
from mindspore import jit
from mindspore import Tensor
from mindspore.ops import operations as P
from mindspore.ops import composite as C
from mindspore.common.parameter import Parameter, ParameterTuple
from mindspore.communication.management import init, NCCL_WORLD_COMM_GROUP, get_rank, get_group_size

class Actor(nn.Cell):

    def __init__(self, msrl, rank, duration, episode):
        super(Actor, self).__init__()
        self.msrl = msrl
        self.rank = rank
        self.worker_num = msrl.proc_num
        self.total_env = msrl.collect_environment.num_environment
        self.env_per_actor = msrl.collect_environment.num_env_per_worker
        self.index_start = (self.rank - 1) * self.env_per_actor
        self.index_end = self.rank * self.env_per_actor
        step_input_shape = msrl.collect_environment.step_input_shape[0]
        step_input_dtype = msrl.collect_environment.step_input_dtype[0]
        shape = list(step_input_shape)
        shape[0] = self.total_env
        self.action_placeholder = Tensor(np.zeros(shape), step_input_dtype)
        self.episode = episode
        self.duration = duration
        self.allgather = P.AllGather(group=NCCL_WORLD_COMM_GROUP)
        self.broadcast = P.Broadcast(root_rank=0, group=NCCL_WORLD_COMM_GROUP)
        self.depend = P.Depend()

    @mindspore.jit
    def gather_state(self):
        pass
        return state

    @mindspore.jit
    def kernel(self):
        pass
        return reward

    def run(self):
        print("Start actor run ----- episode ", self.episode)
        for i in range(self.episode):
            res = self.gather_state()
            for j in range(self.duration):
                res = self.kernel()
            print("actor episode", i)

class Learner(nn.Cell):

    def __init__(self, msrl, rank, duration, episode):
        super(Learner, self).__init__()
        self.msrl = msrl
        self.rank = rank
        self.total_env = msrl.collect_environment.num_environment
        self.env_per_actor = msrl.collect_environment.num_env_per_worker
        self.index_start = (self.rank + 1) * self.env_per_actor
        self.episode = episode
        self.duration = duration
        self.zero = Tensor(0, mindspore.float32)
        self.assign = P.Assign()
        self.squeeze = P.Squeeze()
        self.mod = P.Mod()
        self.equal = P.Equal()
        self.less = P.Less()
        self.reduce_mean = P.ReduceMean()
        self.print = P.Print()
        self.depend = P.Depend()
        self.allgather = P.AllGather(group=NCCL_WORLD_COMM_GROUP)
        self.broadcast = P.Broadcast(root_rank=0, group=NCCL_WORLD_COMM_GROUP)

        step_output_shape = msrl.collect_environment.step_output_shape
        step_output_dtype = msrl.collect_environment.step_output_dtype
        param_dict = self.__dict__
        for i, p in enumerate(step_output_shape):
            param_dict["placeholder_" + str(i)] = Parameter(Tensor(np.zeros(p), step_output_dtype[i]), name="step_out_" + str(i))

    @mindspore.jit
    def kernel(self):
        pass
        return training_loss

    def run(self):
        print("Start learner run ----- episode ", self.episode)
        for i in range(self.episode):
            res = self.kernel()
            print("learner res ", res)
